wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: allepalma (inverse-perturbation-models) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /lustre/groups/ml01/workspace/alessandro.palma/scportrait/experiements/wandb/run-20250808_113015-eyidag73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-serenity-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/inverse-perturbation-models/scportrait_ot_sweep_distance_tonsilitis_cite_non_unif
wandb: üöÄ View run at https://wandb.ai/inverse-perturbation-models/scportrait_ot_sweep_distance_tonsilitis_cite_non_unif/runs/eyidag73
You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB MIG 3g.20gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-92163b8d-2d3b-5999-bfa6-7aaea52601b1]

  | Name      | Type               | Params | Mode 
---------------------------------------------------------
0 | v_mlp     | TimeConditionedMLP | 2.4 M  | train
1 | criterion | MSELoss            | 0      | train
---------------------------------------------------------
2.4 M     Trainable params
0         Non-trainable params
2.4 M     Total params
9.462     Total estimated model params size (MB)
8         Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
`Trainer.fit` stopped: `max_epochs=2000` reached.
