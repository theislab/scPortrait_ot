wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: allepalma (inverse-perturbation-models) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /lustre/groups/ml01/workspace/alessandro.palma/scportrait/experiements/wandb/run-20250808_113844-81xc5oki
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-dream-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/inverse-perturbation-models/scportrait_ot_sweep_distance_healthy_cite
wandb: üöÄ View run at https://wandb.ai/inverse-perturbation-models/scportrait_ot_sweep_distance_healthy_cite/runs/81xc5oki
You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB MIG 3g.20gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-780ef5d7-fd86-5787-940a-4dbc0e48bcc3]

  | Name      | Type               | Params | Mode 
---------------------------------------------------------
0 | v_mlp     | TimeConditionedMLP | 2.4 M  | train
1 | criterion | MSELoss            | 0      | train
---------------------------------------------------------
2.4 M     Trainable params
0         Non-trainable params
2.4 M     Total params
9.462     Total estimated model params size (MB)
8         Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
submitit WARNING (2025-08-08 12:32:36,612) - Bypassing signal SIGCONT
[2025-08-08T12:32:36.612] error: *** JOB 27773779 ON gpusrv32 CANCELLED AT 2025-08-08T12:32:36 DUE to SIGNAL Terminated ***
[2025-08-08T12:32:36.633] error: *** STEP 27773779.0 ON gpusrv32 CANCELLED AT 2025-08-08T12:32:36 DUE to SIGNAL Terminated ***
[rank: 0] Received SIGTERM: 15
Bypassing SIGTERM: 15
submitit WARNING (2025-08-08 12:32:36,644) - Bypassing signal SIGTERM
--- Logging error ---
Traceback (most recent call last):
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 1104, in emit
    self.flush()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 1084, in flush
    self.stream.flush()
RuntimeError: reentrant call inside <_io.BufferedWriter name='/ictstr01/home/icb/alessandro.palma/environment/scportrait_ot/src/multirun/2025-08-08/11-36-10/0/main.log'>
Call stack:
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/submitit/core/_submit.py", line 11, in <module>
    submitit_main()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/submitit/core/submission.py", line 76, in submitit_main
    process_job(args.folder)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/submitit/core/submission.py", line 55, in process_job
    result = delayed.result()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/submitit/core/utils.py", line 137, in result
    self._result = self.function(*self.args, **self.kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/hydra_plugins/hydra_submitit_launcher/submitit_launcher.py", line 71, in __call__
    return run_job(
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/ictstr01/home/icb/alessandro.palma/environment/scportrait_ot/src/main.py", line 23, in train
    estimator.train()
  File "/ictstr01/home/icb/alessandro.palma/environment/scportrait_ot/src/experiment.py", line 86, in train
    self.trainer_generative.fit(
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 539, in fit
    call._call_and_handle_interrupt(
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 575, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 982, in _run
    results = self._run_stage()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1026, in _run_stage
    self.fit_loop.run()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 150, in run
    self.advance(data_fetcher)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 320, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 171, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1302, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/torch/optim/optimizer.py", line 493, in wrapper
    out = func(*args, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
    loss = closure()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 323, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/ictstr01/home/icb/alessandro.palma/environment/scportrait_ot/src/model.py", line 68, in training_step
    return self._step(batch, "train")
  File "/ictstr01/home/icb/alessandro.palma/environment/scportrait_ot/src/model.py", line 99, in _step
    self.log_dict(metrics, prog_bar=True)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 605, in log_dict
    self.log(
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 521, in log
    results.log(
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 745, in _fn
    return fn(*args, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py", line 401, in log
    meta.sync = _Sync(_should=sync_dist, fn=sync_dist_fn, _group=sync_dist_group, rank_zero_only=rank_zero_only)
  File "<string>", line 8, in __init__
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py", line 58, in __post_init__
    self._generate_sync_fn()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py", line 95, in _generate_sync_fn
    self._fn: Callable = partial(fn, reduce_op=self.op, group=self.group)  # type: ignore[arg-type,operator,misc]
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py", line 80, in group
    @property
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/submitit/core/job_environment.py", line 196, in bypass
    self._logger.warning(f"Bypassing signal {signal.Signals(signum).name}")
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 1489, in warning
    self._log(WARNING, msg, args, **kwargs)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 1624, in _log
    self.handle(record)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 1634, in handle
    self.callHandlers(record)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 1696, in callHandlers
    hdlr.handle(record)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 968, in handle
    self.emit(record)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 1218, in emit
    StreamHandler.emit(self, record)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 1104, in emit
    self.flush()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/logging/__init__.py", line 1084, in flush
    self.stream.flush()
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/signal_connector.py", line 33, in __call__
    signal_handler(signum, frame)
  File "/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/submitit/core/job_environment.py", line 196, in bypass
    self._logger.warning(f"Bypassing signal {signal.Signals(signum).name}")
Message: 'Bypassing signal SIGTERM'
Arguments: ()
