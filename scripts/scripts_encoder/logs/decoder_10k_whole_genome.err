/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/docrep/decorators.py:43: SyntaxWarning: 'param_categorical_covariate_keys' is not a valid key!
  doc = func(self, args[0].__doc__, *args[1:], **kwargs)
/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/docrep/decorators.py:43: SyntaxWarning: 'param_continuous_covariate_keys' is not a valid key!
  doc = func(self, args[0].__doc__, *args[1:], **kwargs)
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: allepalma (inverse-perturbation-models) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /home/icb/alessandro.palma/environment/scportrait_ot/project_folder/experiements/wandb/run-20250828_165905-b7ohr3hu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-grass-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/inverse-perturbation-models/decoder_cite_10k_whole_genome
wandb: üöÄ View run at https://wandb.ai/inverse-perturbation-models/decoder_cite_10k_whole_genome/runs/b7ohr3hu
/home/icb/alessandro.palma/miniconda3/envs/sc_exp_design/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python main_autoencoder_train.py adata_path=/home/icb/aless ...
You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name         | Type | Params | Mode 
----------------------------------------------
0 | decoder      | MLP  | 4.5 M  | train
  | other params | n/a  | 17.3 K | n/a  
----------------------------------------------
4.5 M     Trainable params
0         Non-trainable params
4.5 M     Total params
18.157    Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode
`Trainer.fit` stopped: `max_epochs=100` reached.
